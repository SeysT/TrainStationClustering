{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def load_csv(csv_filename, columns, to_flatten, value):\n",
    "    with open(csv_filename, 'r', newline='\\n') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        \n",
    "        data = {}\n",
    "        header = {elt: index for index, elt in enumerate(next(csv_reader))}\n",
    "        flattens = set()\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            key = tuple(row[header[column]] for column in columns)\n",
    "            flattens.add(row[header[to_flatten]])\n",
    "            try:\n",
    "                data[key][row[header[to_flatten]]] = row[header[value]]\n",
    "            except KeyError:\n",
    "                data[key] = {row[header[to_flatten]]: row[header[value]]}\n",
    "                \n",
    "        df_dict = {elt:  [] for elt in columns}\n",
    "        df_dict.update({elt: [] for elt in flattens})\n",
    "    \n",
    "        for key, values in data.items():\n",
    "            for index, column in enumerate(columns):\n",
    "                df_dict[column].append(key[index])\n",
    "            for flatten in flattens:\n",
    "                df_dict[flatten].append(values.get(flatten, 0)) \n",
    "        \n",
    "        return pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_columns = ['LIBELLE_ARRET', 'CAT_JOUR', 'ID_REFA_LDA']\n",
    "p_flatten = 'TRNC_HORR_60'\n",
    "p_value = 'pourc_validations'\n",
    "\n",
    "v_columns = ['LIBELLE_ARRET', 'JOUR', 'ID_REFA_LDA']\n",
    "v_flatten = 'CATEGORIE_TITRE'\n",
    "v_value = 'NB_VALD'\n",
    "\n",
    "profile_s1 = load_csv('Data/validations-profils-horaires-2017s1.csv', p_columns, p_flatten, p_value)\n",
    "profile_s2 = load_csv('Data/validations-profils-horaires-2017s2.csv', p_columns, p_flatten, p_value)\n",
    "\n",
    "validation_s1 = load_csv('Data/validations-nombre-par-jour-2017s1.csv', v_columns, v_flatten, v_value)\n",
    "validation_s2 = load_csv('Data/validations-nombre-par-jour-2017s2.csv', v_columns, v_flatten, v_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df, float_columns, not_defined):\n",
    "    to_return = df.copy()\n",
    "    \n",
    "    to_return = to_return.drop(not_defined, axis=1)\n",
    "    to_return = to_return.drop(to_return[to_return['ID_REFA_LDA'] == ''].index)\n",
    "    \n",
    "    for column in float_columns:\n",
    "        to_return[column] = to_return[column].astype(float)\n",
    "    \n",
    "    return to_return\n",
    "\n",
    "TRC_HORR = [\n",
    "    '0H-1H', '1H-2H', '2H-3H', '3H-4H', '4H-5H', '5H-6H',\n",
    "    '6H-7H', '7H-8H', '8H-9H', '9H-10H', '10H-11H', '11H-12H',\n",
    "    '12H-13H', '13H-14H', '14H-15H', '15H-16H', '16H-17H', '17H-18H',\n",
    "    '18H-19H', '19H-20H', '20H-21H', '21H-22H', '22H-23H', '23H-0H',\n",
    "]\n",
    "\n",
    "CATEGORIE_TITRE = ['AMETHYSTE', 'AUTRE TITRE', 'FGT', 'IMAGINE R', 'NAVIGO', 'TST']\n",
    "\n",
    "profile_s1 = clean(profile_s1, TRC_HORR, 'ND')\n",
    "profile_s2 = clean(profile_s2, TRC_HORR, 'ND')\n",
    "\n",
    "validation_s1 = validation_s1.replace('Moins de 5', 5).replace('', 0)\n",
    "validation_s2 = validation_s2.replace('Moins de 5', 5).replace('', 0)\n",
    "\n",
    "validation_s1 = clean(validation_s1, CATEGORIE_TITRE, 'NON DEFINI')\n",
    "validation_s2 = clean(validation_s2, CATEGORIE_TITRE, 'NON DEFINI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat profile datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_profile(df):\n",
    "    def apply(row):\n",
    "        id = row.ID_REFA_LDA\n",
    "        cat_jour = row.CAT_JOUR\n",
    "        try:\n",
    "            new_row = df[(df.ID_REFA_LDA == id) & (df.CAT_JOUR == cat_jour)].iloc[0]\n",
    "        except:\n",
    "            new_row = row\n",
    "            \n",
    "        for hour in TRC_HORR:\n",
    "            row[hour] = (row[hour] + new_row[hour]) / 2\n",
    "        return row\n",
    "    return apply\n",
    "    \n",
    "profile = profile_s2.apply(concat_profile(profile_s1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIE_JOUR = ['JOHV', 'SAHV', 'JOVS', 'SAVS', 'DIJFP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Validations Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation = pd.concat([validation_s1, validation_s2])\n",
    "\n",
    "# TODO: write this in utils functions\n",
    "validation['TOTAL_VALID'] = sum(validation[titre] for titre in CATEGORIE_TITRE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt validations number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturday = 6\n",
    "sunday = 7\n",
    "week_holydays = [6, 7, 14, 15, 28, 29, 30, 31, 32, 33, 34, 35, 43, 44, 52]\n",
    "jours_feries = [\n",
    "    '2017-01-01', '2017-04-16', '2017-04-17', '2017-05-01',\n",
    "    '2017-05-08', '2017-05-25', '2017-06-05', '2017-07-14',\n",
    "    '2017-08-15', '2017-11-01', '2017-11-11', '2017-12-25'\n",
    "]\n",
    "\n",
    "def get_cat_jour(row):\n",
    "    if row.JOUR in jours_feries:\n",
    "        return 'DIJFP'\n",
    "    \n",
    "    date = datetime.strptime(row.JOUR, '%Y-%m-%d')\n",
    "    if date.isocalendar()[1] == sunday:\n",
    "        return 'DIJFP'\n",
    "    elif date.isocalendar()[1] == saturday:\n",
    "        if date.isocalendar()[2] in week_holydays:\n",
    "            return 'SAVS'\n",
    "        return 'SAHV'\n",
    "    \n",
    "    if date.isocalendar()[2] in week_holydays:\n",
    "        return 'JOVS'\n",
    "    return 'JOHV'\n",
    "\n",
    "validation = pd.concat([validation_s1, validation_s2])\n",
    "validation['CAT_JOUR'] = validation.apply(get_cat_jour, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9d9dfe4edef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     val_day = sum(validation.loc[\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID_REFA_LDA'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mID_REFA_LDA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CAT_JOUR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcat_jour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     ].iloc[:, 3])\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval_day\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "Data = profile.copy()\n",
    "for i in range(Data.shape[0]):\n",
    "    ID_REFA_LDA = Data.iloc[i,25]\n",
    "    val_day = sum(validation.loc[validation['ID_REFA_LDA'] == ID_REFA_LDA,:].iloc[:, 3])\n",
    "    for h in range(24):\n",
    "        Data.iloc[i, h] = int(Data.iloc[i, h] * val_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'68419'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dac-project",
   "language": "python",
   "name": "dac-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
