{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auteurs : Hachemin Pierre-Yves et Seys Thibaut\n",
    "\n",
    "Date : 25/04/2018\n",
    "\n",
    "Cours : IS3024AB - Data Mining\n",
    "\n",
    "# Etude sur le transport en Ile-de-France\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "\n",
    "    + [Contexte et objectifs](#Contexte-et-objectifs)\n",
    "    \n",
    "    + [Requirements](#Requirements)\n",
    "\n",
    "* [Datasets](#Datasets)\n",
    "\n",
    "    + [Description des datasets utilisées](#Composition-des-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Contexte et objectifs\n",
    "\n",
    "Pour notre projet de Data Mining, nous avons choisi d'explorer les données issues de la palteforme Open Data du Syndicat des Transports d'Ile-de-France (STIF) disponible à [cette adresse](https://opendata.stif.info/). Nous avons décidé d'explorer les données issues de la validation des voyageurs sur les différents réseaux ferrés d'Ile-de-France.\n",
    "\n",
    "Notre objectif est de mener une double étude sur les caractéristiques actuelles du réseau ferré et de son efficacité. Nous allons donc d'une part appliquer des algorithmes de clustering sur les différentes stations du réseau afin de mettre en évidence les profils types. Nous allons d'autre part essayer de recréer des lignes de transports reliant les différentes stations et comparer les résultats obtenus au réseau actuellement en place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "Pour que notre projet fonctionne correctement, nous avons besoin d'importer les libraries suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "### Description des datasets\n",
    "\n",
    "Parmis les jeux de données mis à disposition par la plateforme Open Data du STIF, nous avons choisi d'utiliser les 4 types de datasets suivants :\n",
    "\n",
    "- [validations-nombre-par-jour-2017s1](https://opendata.stif.info/explore/dataset/validations-sur-le-reseau-ferre-nombre-de-validations-par-jour-1er-sem/) et [validations-nombre-par-jour-2017s2](https://opendata.stif.info/explore/dataset/validations-sur-le-reseau-ferre-profils-horaires-par-jour-type-2e-sem/) : contiennent le nombre de validations par jour par station par catégorie de titre de transport pour chaqeu semestre de 2017.\n",
    "\n",
    "- [validations-profils-horaires-2017s1](https://opendata.stif.info/explore/dataset/validations-sur-le-reseau-ferre-profils-horaires-par-jour-type-1er-sem/) et [validations-profils-horaires-2017s2](https://opendata.stif.info/explore/dataset/validations-sur-le-reseau-ferre-profils-horaires-par-jour-type-2e-sem/) : contiennent les pourcentages moyens de validation par tranche horaire à la station donnée suivant le type de journée (jour ordinaire, dimanche, etc...)  pour chaque semestre de 2017.\n",
    "\n",
    "- [emplacement-des-gares-idf](https://opendata.stif.info/explore/dataset/emplacement-des-gares-idf/) : contient les emplacements de l'ensemble des stations du réseau ferré d'Ile-de-France.\n",
    "\n",
    "- [referentiel-arret-tc-idf-](https://opendata.stif.info/explore/dataset/referentiel-arret-tc-idf/) : recense l'ensemble des stations des réseaux de surface et ferré de transport d'Ile-de-France suivant différents niveaux de granularités.\n",
    "\n",
    "Tous ces datasets sont disponibles dans le dossier `Data` sous forme de fichiers csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition des datasets\n",
    "\n",
    "Nous allons décrire dans cette partie les différents champs que nous allons utiliser pour chaque type de \n",
    "\n",
    "#### **Datasets du nombre de validations par jour**\n",
    "\n",
    "Les champs que nous avons choisi de garder sont représentés dans le tableau suivant :\n",
    "\n",
    "| Nom du champs | Description | Valeur |\n",
    "|---------------|-------------|--------|\n",
    "| LIBELLE_ARRET | Libellée de l'arrêt | string |\n",
    "| ID_REFA_LDA | Id de l'arrêt | float |\n",
    "| JOUR | Jour de l'année | string |\n",
    "| CATEGORIE_TITRE | Catégorie du titre | AMETHYSTE, AUTRE TITRE, FGT, IMAGINE R, NAVIGO, TST |\n",
    "| NB_VALD | Nombre de validations | int ou 'Moins de 5' |\n",
    "\n",
    "#### **Datasets du profil de validation**\n",
    "\n",
    "| Nom du champs | Description | Valeur |\n",
    "|---------------|-------------|--------|\n",
    "| LIBELLE_ARRET | Libellée de l'arrêt | string |\n",
    "| ID_REFA_LDA | Id de l'arrêt | float |\n",
    "| CAT_JOUR | Type de journée | JOHV, SAHV, JOVS, SAVS, DIJFP |\n",
    "| TRNC_HORR_60 | Tranche horaire | Interval (ex: 1H - 2H) |\n",
    "| pourc_validations | Pourcentage de validations | float |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dac-project",
   "language": "python",
   "name": "dac-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
